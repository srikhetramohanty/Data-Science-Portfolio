{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "furnished-executive",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:18.338189Z",
     "iopub.status.busy": "2021-07-29T06:38:18.337313Z",
     "iopub.status.idle": "2021-07-29T06:38:19.346741Z",
     "shell.execute_reply": "2021-07-29T06:38:19.346121Z",
     "shell.execute_reply.started": "2021-07-29T06:36:39.645510Z"
    },
    "papermill": {
     "duration": 1.040184,
     "end_time": "2021-07-29T06:38:19.346906",
     "exception": false,
     "start_time": "2021-07-29T06:38:18.306722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/train_data.csv\n",
      "/kaggle/input/titanic/test_data.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-lotus",
   "metadata": {
    "papermill": {
     "duration": 0.019513,
     "end_time": "2021-07-29T06:38:19.386961",
     "exception": false,
     "start_time": "2021-07-29T06:38:19.367448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing titanic data from the below link:\n",
    "https://www.kaggle.com/azeembootwala/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "british-scope",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:19.437525Z",
     "iopub.status.busy": "2021-07-29T06:38:19.436837Z",
     "iopub.status.idle": "2021-07-29T06:38:19.489508Z",
     "shell.execute_reply": "2021-07-29T06:38:19.489039Z",
     "shell.execute_reply.started": "2021-07-29T06:36:40.712558Z"
    },
    "papermill": {
     "duration": 0.082983,
     "end_time": "2021-07-29T06:38:19.489642",
     "exception": false,
     "start_time": "2021-07-29T06:38:19.406659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Emb_1</th>\n",
       "      <th>Emb_2</th>\n",
       "      <th>Emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Sex     Age      Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0            1         0    1  0.2750  0.014151         0         0         1   \n",
       "1            2         1    0  0.4750  0.139136         1         0         0   \n",
       "2            3         1    0  0.3250  0.015469         0         0         1   \n",
       "3            4         1    0  0.4375  0.103644         1         0         0   \n",
       "4            5         0    1  0.4375  0.015713         0         0         1   \n",
       "\n",
       "   Family_size  Emb_1  Emb_2  Emb_3  \n",
       "0          0.1      0      0      1  \n",
       "1          0.1      1      0      0  \n",
       "2          0.0      0      0      1  \n",
       "3          0.1      0      0      1  \n",
       "4          0.0      0      0      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ads_pre = pd.read_csv('../input/titanic/train_data.csv')\n",
    "input_ads_pre.drop(columns=['Unnamed: 0','Title_1','Title_2','Title_3','Title_4'],inplace=True) #Dropping un-necessary columns\n",
    "#-----------------------------------------------------------------\n",
    "print(input_ads_pre.shape)\n",
    "input_ads_pre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-dressing",
   "metadata": {
    "papermill": {
     "duration": 0.023346,
     "end_time": "2021-07-29T06:38:19.533972",
     "exception": false,
     "start_time": "2021-07-29T06:38:19.510626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Null Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "closed-contemporary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:19.588400Z",
     "iopub.status.busy": "2021-07-29T06:38:19.587771Z",
     "iopub.status.idle": "2021-07-29T06:38:19.592328Z",
     "shell.execute_reply": "2021-07-29T06:38:19.591852Z",
     "shell.execute_reply.started": "2021-07-29T06:36:40.767195Z"
    },
    "papermill": {
     "duration": 0.037617,
     "end_time": "2021-07-29T06:38:19.592460",
     "exception": false,
     "start_time": "2021-07-29T06:38:19.554843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Emb_1</th>\n",
       "      <th>Emb_2</th>\n",
       "      <th>Emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Sex  Age  Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0            0         0    0    0     0         0         0         0   \n",
       "\n",
       "   Family_size  Emb_1  Emb_2  Emb_3  \n",
       "0            0      0      0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(input_ads_pre.isnull().sum()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-matter",
   "metadata": {
    "papermill": {
     "duration": 0.020673,
     "end_time": "2021-07-29T06:38:19.634139",
     "exception": false,
     "start_time": "2021-07-29T06:38:19.613466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Describing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "institutional-compiler",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:19.686201Z",
     "iopub.status.busy": "2021-07-29T06:38:19.685281Z",
     "iopub.status.idle": "2021-07-29T06:38:19.728619Z",
     "shell.execute_reply": "2021-07-29T06:38:19.728149Z",
     "shell.execute_reply.started": "2021-07-29T06:36:40.784899Z"
    },
    "papermill": {
     "duration": 0.073806,
     "end_time": "2021-07-29T06:38:19.728793",
     "exception": false,
     "start_time": "2021-07-29T06:38:19.654987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Emb_1</th>\n",
       "      <th>Emb_2</th>\n",
       "      <th>Emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "      <td>792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>396.500000</td>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.368244</td>\n",
       "      <td>0.064677</td>\n",
       "      <td>0.243687</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.547980</td>\n",
       "      <td>0.088636</td>\n",
       "      <td>0.185606</td>\n",
       "      <td>0.092172</td>\n",
       "      <td>0.720960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>228.774999</td>\n",
       "      <td>0.487223</td>\n",
       "      <td>0.477980</td>\n",
       "      <td>0.162994</td>\n",
       "      <td>0.100987</td>\n",
       "      <td>0.429577</td>\n",
       "      <td>0.406373</td>\n",
       "      <td>0.498007</td>\n",
       "      <td>0.154485</td>\n",
       "      <td>0.389034</td>\n",
       "      <td>0.289451</td>\n",
       "      <td>0.448811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>198.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>396.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>594.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.061045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>792.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived         Sex         Age        Fare  \\\n",
       "count   792.000000  792.000000  792.000000  792.000000  792.000000   \n",
       "mean    396.500000    0.386364    0.647727    0.368244    0.064677   \n",
       "std     228.774999    0.487223    0.477980    0.162994    0.100987   \n",
       "min       1.000000    0.000000    0.000000    0.008375    0.000000   \n",
       "25%     198.750000    0.000000    0.000000    0.275000    0.015469   \n",
       "50%     396.500000    0.000000    1.000000    0.350000    0.028302   \n",
       "75%     594.250000    1.000000    1.000000    0.437500    0.061045   \n",
       "max     792.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         Pclass_1    Pclass_2    Pclass_3  Family_size       Emb_1  \\\n",
       "count  792.000000  792.000000  792.000000   792.000000  792.000000   \n",
       "mean     0.243687    0.208333    0.547980     0.088636    0.185606   \n",
       "std      0.429577    0.406373    0.498007     0.154485    0.389034   \n",
       "min      0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000     0.000000    0.000000   \n",
       "50%      0.000000    0.000000    1.000000     0.000000    0.000000   \n",
       "75%      0.000000    0.000000    1.000000     0.100000    0.000000   \n",
       "max      1.000000    1.000000    1.000000     1.000000    1.000000   \n",
       "\n",
       "            Emb_2       Emb_3  \n",
       "count  792.000000  792.000000  \n",
       "mean     0.092172    0.720960  \n",
       "std      0.289451    0.448811  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    1.000000  \n",
       "75%      0.000000    1.000000  \n",
       "max      1.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ads_pre.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-baseline",
   "metadata": {
    "papermill": {
     "duration": 0.021495,
     "end_time": "2021-07-29T06:38:19.773116",
     "exception": false,
     "start_time": "2021-07-29T06:38:19.751621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Describing the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "linear-sense",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:19.823512Z",
     "iopub.status.busy": "2021-07-29T06:38:19.822747Z",
     "iopub.status.idle": "2021-07-29T06:38:19.826412Z",
     "shell.execute_reply": "2021-07-29T06:38:19.826781Z",
     "shell.execute_reply.started": "2021-07-29T06:36:40.840273Z"
    },
    "papermill": {
     "duration": 0.03241,
     "end_time": "2021-07-29T06:38:19.826948",
     "exception": false,
     "start_time": "2021-07-29T06:38:19.794538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    486\n",
       "1    306\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total survived vs not-survived split in the training data\n",
    "input_ads_pre['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-lodge",
   "metadata": {
    "papermill": {
     "duration": 0.021063,
     "end_time": "2021-07-29T06:38:19.869411",
     "exception": false,
     "start_time": "2021-07-29T06:38:19.848348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Shuffling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "supported-pointer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:19.927411Z",
     "iopub.status.busy": "2021-07-29T06:38:19.918772Z",
     "iopub.status.idle": "2021-07-29T06:38:19.931866Z",
     "shell.execute_reply": "2021-07-29T06:38:19.932321Z",
     "shell.execute_reply.started": "2021-07-29T06:36:40.849735Z"
    },
    "papermill": {
     "duration": 0.041847,
     "end_time": "2021-07-29T06:38:19.932485",
     "exception": false,
     "start_time": "2021-07-29T06:38:19.890638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Family_size</th>\n",
       "      <th>Emb_1</th>\n",
       "      <th>Emb_2</th>\n",
       "      <th>Emb_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.108215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.051822</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>624</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Sex     Age      Fare  Pclass_1  Pclass_2  Pclass_3  \\\n",
       "0          371         1    1  0.3125  0.108215         1         0         0   \n",
       "1          556         0    1  0.7750  0.051822         1         0         0   \n",
       "2          624         0    1  0.2625  0.015330         0         0         1   \n",
       "\n",
       "   Family_size  Emb_1  Emb_2  Emb_3  \n",
       "0          0.1      1      0      0  \n",
       "1          0.0      0      0      1  \n",
       "2          0.0      0      0      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "#np.random.seed(100)\n",
    "\n",
    "#----------------------------------------------------\n",
    "input_ads = shuffle(input_ads_pre,random_state=100)\n",
    "print(input_ads.shape)\n",
    "input_ads = input_ads.reset_index(drop=True)\n",
    "input_ads.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-banks",
   "metadata": {
    "papermill": {
     "duration": 0.022151,
     "end_time": "2021-07-29T06:38:19.976715",
     "exception": false,
     "start_time": "2021-07-29T06:38:19.954564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Manipulation of Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "golden-celebrity",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:20.033248Z",
     "iopub.status.busy": "2021-07-29T06:38:20.032566Z",
     "iopub.status.idle": "2021-07-29T06:38:20.049503Z",
     "shell.execute_reply": "2021-07-29T06:38:20.050318Z",
     "shell.execute_reply.started": "2021-07-29T06:36:40.875442Z"
    },
    "papermill": {
     "duration": 0.051205,
     "end_time": "2021-07-29T06:38:20.050580",
     "exception": false,
     "start_time": "2021-07-29T06:38:19.999375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Sex', 'Age', 'Fare', 'Pclass_1', 'Pclass_2', 'Pclass_3',\n",
      "       'Family_size', 'Emb_1', 'Emb_2', 'Emb_3'],\n",
      "      dtype='object')\n",
      "Train % of total data: 88.78923766816143\n",
      "(792, 11)\n",
      "(100, 11)\n",
      "(792, 1)\n"
     ]
    }
   ],
   "source": [
    "target = 'Survived' #To predict\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Splitting into X & Y datasets (supervised training)\n",
    "X = input_ads[[cols for cols in list(input_ads.columns) if target not in cols]]\n",
    "y = input_ads[target]\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Since test data is already placed in the input folder separately, we will just import it\n",
    "test_ads_pre = pd.read_csv('../input/titanic/test_data.csv')\n",
    "test_ads_pre.drop(columns=['Unnamed: 0','Title_1','Title_2','Title_3','Title_4'],inplace=True) #Dropping un-necessary columns\n",
    "test_ads = shuffle(test_ads_pre,random_state=100)\n",
    "test_ads = test_ads.reset_index(drop=True)\n",
    "\n",
    "#Splitting into X & Y datasets (supervised training)\n",
    "X_test = test_ads[[cols for cols in list(test_ads.columns) if target not in cols]]\n",
    "y_test = test_ads[target]\n",
    "\n",
    "print('Train % of total data:',100 * X.shape[0]/(X.shape[0] + X_test.shape[0]))\n",
    "#--------------------------------------------------------------------------------\n",
    "#Manipulation of datasets for convenience and consistency\n",
    "X_arr = np.array(X)\n",
    "X_test_arr = np.array(X_test)\n",
    "\n",
    "y_arr = np.array(y).reshape(X_arr.shape[0],1)\n",
    "y_test_arr = np.array(y_test).reshape(X_test_arr.shape[0],1)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "#Basic Summary\n",
    "print(X_arr.shape)\n",
    "print(X_test_arr.shape)\n",
    "print(y_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-breach",
   "metadata": {
    "papermill": {
     "duration": 0.021991,
     "end_time": "2021-07-29T06:38:20.096718",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.074727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Decision Tree Classifier from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-advocate",
   "metadata": {
    "papermill": {
     "duration": 0.022474,
     "end_time": "2021-07-29T06:38:20.141409",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.118935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## UDF to calculate gini index of each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "japanese-opinion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:20.191551Z",
     "iopub.status.busy": "2021-07-29T06:38:20.190906Z",
     "iopub.status.idle": "2021-07-29T06:38:20.192861Z",
     "shell.execute_reply": "2021-07-29T06:38:20.193322Z",
     "shell.execute_reply.started": "2021-07-29T06:36:40.906202Z"
    },
    "papermill": {
     "duration": 0.029821,
     "end_time": "2021-07-29T06:38:20.193486",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.163665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gini_node(arr_,k):\n",
    "\n",
    "    class_elem_total = 0\n",
    "    for class_ in k: #Iterating for each class in the node\n",
    "        class_elem = (np.sum((arr_==class_).astype(int)))/len(arr_)\n",
    "        class_elem = class_elem**2\n",
    "        class_elem_total = class_elem_total + class_elem \n",
    "        \n",
    "    gini_node = 1 - class_elem_total\n",
    "    return gini_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-crawford",
   "metadata": {
    "papermill": {
     "duration": 0.022336,
     "end_time": "2021-07-29T06:38:20.238568",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.216232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## UDF for Gini index of a split (Weighted by the leafs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "treated-burke",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:20.286620Z",
     "iopub.status.busy": "2021-07-29T06:38:20.286033Z",
     "iopub.status.idle": "2021-07-29T06:38:20.291287Z",
     "shell.execute_reply": "2021-07-29T06:38:20.291725Z",
     "shell.execute_reply.started": "2021-07-29T06:36:40.914183Z"
    },
    "papermill": {
     "duration": 0.030988,
     "end_time": "2021-07-29T06:38:20.291889",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.260901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gini_split(left_arr,right_arr,k):\n",
    "\n",
    "    #Total obs in each node\n",
    "    m_left = len(left_arr)\n",
    "    m_right = len(right_arr)\n",
    "    m_total_node = m_left + m_right  \n",
    "\n",
    "    #Calculating gini index for each \n",
    "    gini_left = gini_node(left_arr,k)\n",
    "    #print(gini_left)\n",
    "    gini_right = gini_node(right_arr,k)\n",
    "    #print(gini_right)\n",
    "    \n",
    "    #Calculation of gini for the split\n",
    "    if m_left==0:\n",
    "        gini_split = ((m_right/m_total_node) * gini_right)\n",
    "        \n",
    "    elif m_right==0:\n",
    "        gini_split = ((m_left/m_total_node) * gini_left)\n",
    "    \n",
    "    elif (m_left>0) & (m_right>0):\n",
    "        gini_split = ((m_left/m_total_node) * gini_left) + ((m_right/m_total_node) * gini_right)\n",
    "\n",
    "    return gini_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-assets",
   "metadata": {
    "papermill": {
     "duration": 0.022446,
     "end_time": "2021-07-29T06:38:20.337058",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.314612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## UDF for inding best split for a feature (Greedy Exact Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unknown-seating",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:20.385542Z",
     "iopub.status.busy": "2021-07-29T06:38:20.384873Z",
     "iopub.status.idle": "2021-07-29T06:38:20.394766Z",
     "shell.execute_reply": "2021-07-29T06:38:20.395313Z",
     "shell.execute_reply.started": "2021-07-29T06:36:40.926303Z"
    },
    "papermill": {
     "duration": 0.035917,
     "end_time": "2021-07-29T06:38:20.395483",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.359566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_split_algo(data,col_idx,min_samples_split=2,min_samples_leaf=2):\n",
    "    \n",
    "    assert len(data[:,col_idx])>=min_samples_split, \"Data Insufficient - Include more data or reduce min_samples_split hyper-param\"\n",
    "    \n",
    "    k = np.unique(data[:,-1]) #Unique of all classes going into to function\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    #To be used for thresholds\n",
    "    unique_vals = np.unique(data[:,col_idx])\n",
    "    \n",
    "    #print('Total unique vals in the column :',len(unique_vals))\n",
    "    \n",
    "    if len(unique_vals)>1:\n",
    "\n",
    "        gini_node_ = gini_node(data[:,-1],k)\n",
    "\n",
    "        splits_gini_dict = {}\n",
    "        thresholds_discarded = []\n",
    "\n",
    "        #------------------------------------------------------------------------------------------------------\n",
    "        for threshold in unique_vals: #For each threshold possible\n",
    "\n",
    "            #print('-------- Threshold : -------',threshold)\n",
    "\n",
    "            left_split = data[data[:,col_idx]<=threshold] #Left extension of tree\n",
    "            left_split_target = left_split[:,-1]\n",
    "            #print('Len left :',len(left_split_target))\n",
    "\n",
    "            right_split = data[data[:,col_idx]>threshold] #Right extension of tree\n",
    "            right_split_target = right_split[:,-1]\n",
    "            #print('Len right :',len(right_split_target))\n",
    "\n",
    "            #--------------------------------------------------------------------------------------------------\n",
    "            if (len(left_split_target)>=min_samples_leaf) & (len(right_split_target)>=min_samples_leaf): #Condition on mininum samples for a split to be eligible\n",
    "                \n",
    "                #Calculating the gini index of the split\n",
    "                gini_split_ = gini_split(left_arr=left_split_target,\n",
    "                                         right_arr=right_split_target,\n",
    "                                         k=k)\n",
    "                #print(gini_split_)\n",
    "                    \n",
    "                splits_gini_dict.update({threshold : gini_split_})\n",
    "\n",
    "            else:\n",
    "                #Discarding the threshold if condition not met\n",
    "                thresholds_discarded.append(threshold)\n",
    "\n",
    "        #print('Thresholds discarded :',thresholds_discarded)\n",
    "        #print(splits_gini_list)\n",
    "        #------------------------------------------------------------------------------------------------------\n",
    "        # Finding min value keys in dictionary\n",
    "\n",
    "        #assert len(splits_gini_dict)>0, \"No thresholds evaluated\"\n",
    "        \n",
    "        \n",
    "        #Condition to avoid empty dictionary (if no split is feasible)\n",
    "        if len(splits_gini_dict)>0:\n",
    "\n",
    "            min_gini = min(splits_gini_dict.values())\n",
    "            split_val = [key for key in splits_gini_dict if splits_gini_dict[key] == min_gini]\n",
    "            #print('Min Score :',min_gini)\n",
    "            #print('Min Score Split Value :',split_val[0])\n",
    "            #------------------------------------------------------------------------------------------------------\n",
    "            split_col_map_dict = {col_idx : split_val[0]}\n",
    "            best_score_col_map_dict = {col_idx : min_gini}\n",
    "\n",
    "            return split_col_map_dict,best_score_col_map_dict\n",
    "        \n",
    "        else:\n",
    "            #print('1. No Split')\n",
    "            split_col_map_dict = {col_idx : np.nan}\n",
    "            best_score_col_map_dict = {col_idx : np.nan}\n",
    "        \n",
    "            return split_col_map_dict,best_score_col_map_dict\n",
    "            \n",
    "    \n",
    "    else:\n",
    "        #print('2. No Split')\n",
    "        split_col_map_dict = {col_idx : np.nan}\n",
    "        best_score_col_map_dict = {col_idx : np.nan}\n",
    "        \n",
    "        #Returning dict of the best split and their best score with their col idx as key\n",
    "        return split_col_map_dict,best_score_col_map_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-oasis",
   "metadata": {
    "papermill": {
     "duration": 0.022089,
     "end_time": "2021-07-29T06:38:20.440277",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.418188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## UDF for overall best split finding algorithm (Greedy Exact Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "political-charm",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:20.488291Z",
     "iopub.status.busy": "2021-07-29T06:38:20.487687Z",
     "iopub.status.idle": "2021-07-29T06:38:20.493091Z",
     "shell.execute_reply": "2021-07-29T06:38:20.493518Z",
     "shell.execute_reply.started": "2021-07-29T06:36:40.943342Z"
    },
    "papermill": {
     "duration": 0.030833,
     "end_time": "2021-07-29T06:38:20.493672",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.462839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def overall_split(data,col_idx_eligible):\n",
    "    \n",
    "    scores_dict = {}\n",
    "    split_val_dict = {}\n",
    "    #col_idx_eligible = list(range(data.shape[1])) \n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------\n",
    "    #For a subset of columns required\n",
    "    for col_idx in col_idx_eligible:\n",
    "\n",
    "        #print('\\n#--------- Index of columns :',col_idx,' ---------#\\n')\n",
    "        #Finding the best split for the feature\n",
    "        split_val_dict_temp,scores_dict_temp = feature_split_algo(data=data,\n",
    "                                                                   col_idx=col_idx)\n",
    "        print(scores_dict_temp)\n",
    "\n",
    "        scores_dict.update(scores_dict_temp)\n",
    "        split_val_dict.update(split_val_dict_temp)\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------\n",
    "    best_score_overall = min(scores_dict.values()) #Extracting the min score across all columns\n",
    "    best_score_col_idx = [key for key in list(scores_dict.keys()) if scores_dict[key]==best_score_overall] #Extracting the col idx with the best score\n",
    "    #print('best_score_col_idx:',best_score_col_idx)\n",
    "    best_col_idx_split_val = split_val_dict[best_score_col_idx[0]]\n",
    "    \n",
    "    #Returning dict of col idx and lsit of best split score and corresponding threshold\n",
    "    return {best_score_col_idx[0] : [best_score_overall,best_col_idx_split_val]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-chain",
   "metadata": {
    "papermill": {
     "duration": 0.022251,
     "end_time": "2021-07-29T06:38:20.538457",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.516206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## UDF for splitting the current dataframe by the best split found out through the above algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fewer-reasoning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:20.586788Z",
     "iopub.status.busy": "2021-07-29T06:38:20.586221Z",
     "iopub.status.idle": "2021-07-29T06:38:20.590785Z",
     "shell.execute_reply": "2021-07-29T06:38:20.591286Z",
     "shell.execute_reply.started": "2021-07-29T06:36:40.962563Z"
    },
    "papermill": {
     "duration": 0.030304,
     "end_time": "2021-07-29T06:38:20.591461",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.561157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_array(arr,arr_y,col_idx,split_val):\n",
    "    \n",
    "    #print('Col idx :',col_idx,'-------> Split value :',split_val)\n",
    "    \n",
    "    #Split for X of data\n",
    "    x_left = arr[arr[:,col_idx]<=split_val]\n",
    "    x_right = arr[arr[:,col_idx]>split_val]\n",
    "    \n",
    "    #Split for Y of data\n",
    "    y_left = arr_y[arr[:,col_idx]<=split_val]\n",
    "    y_right = arr_y[arr[:,col_idx]>split_val]\n",
    "    \n",
    "    return x_left,x_right,col_idx,split_val,y_left,y_right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-museum",
   "metadata": {
    "papermill": {
     "duration": 0.022583,
     "end_time": "2021-07-29T06:38:20.636927",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.614344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Class for the Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "entitled-adapter",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:20.688637Z",
     "iopub.status.busy": "2021-07-29T06:38:20.687949Z",
     "iopub.status.idle": "2021-07-29T06:38:20.708660Z",
     "shell.execute_reply": "2021-07-29T06:38:20.707873Z",
     "shell.execute_reply.started": "2021-07-29T06:36:40.977825Z"
    },
    "papermill": {
     "duration": 0.049557,
     "end_time": "2021-07-29T06:38:20.708817",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.659260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class cart:\n",
    "    \n",
    "    def __init__(self):\n",
    "            print(\"in init\")\n",
    "    \n",
    "    #UDF for CART\n",
    "    def grow_tree(self,x_data,y_data,node_dict,max_depth,feat_idx_list=[0,1,4,5,7,9],min_samples_split=5,min_samples_leaf=2,depth=0,input_ads_=input_ads):\n",
    "        \n",
    "        input_ads_ = input_ads_.drop(columns=target) #Dropping target column\n",
    "        \n",
    "        #To restrict going above max depth\n",
    "        if depth<=max_depth:\n",
    "            \n",
    "            print('#---------------------------------- DEPTH :',depth,' -----------------------------------#')\n",
    "            \n",
    "            #Calculating best split overall\n",
    "            split_dict = overall_split(data=np.append(x_data,y_data,axis=-1),\n",
    "                                       col_idx_eligible=feat_idx_list)\n",
    "\n",
    "            split_col_idx = list(split_dict.keys())[0]\n",
    "            gini_ = list(split_dict.values())[0][0]\n",
    "            split_col_val = list(split_dict.values())[0][1]\n",
    "            \n",
    "            #--------------------------------------------------------------------------------------------------------------\n",
    "            print('1. -------> Entering root_node of depth :',depth)\n",
    "            #Splitting on the best split point found\n",
    "            x_left,x_right,col_idx,split_val,y_left,y_right = split_array(arr=x_data,arr_y=y_data,\n",
    "                                                                          col_idx=split_col_idx,\n",
    "                                                                          split_val=split_col_val)\n",
    "            \n",
    "            #Defining dictionary for the node of tree \n",
    "            node_dict = {'col': input_ads_.columns[split_col_idx], 'col_idx':split_col_idx,\n",
    "                         'threshold':split_col_val,'val': np.mean(y_data),'n_class_0': len(y_data[y_data==0]),\n",
    "                         'n_class_1': len(y_data[y_data==1]),'n_vals':len(y_data)}  # save the information \n",
    "            \n",
    "            #-----------------------------------------------------------------------\n",
    "            print('2. ------->First :\\n',node_dict)\n",
    "\n",
    "            # generate tree for the left hand side data\n",
    "            print('3. -------> Entering left of depth:',depth)\n",
    "            node_dict['left'] = self.grow_tree(x_data=x_left,\n",
    "                                               y_data=y_left,\n",
    "                                               feat_idx_list=feat_idx_list,\n",
    "                                               node_dict={},\n",
    "                                               max_depth=max_depth,\n",
    "                                               min_samples_split=min_samples_split,\n",
    "                                               min_samples_leaf=min_samples_leaf,\n",
    "                                               depth=depth+1)   \n",
    "            #-----------------------------------------------------------------------\n",
    "            if node_dict['left']==None:\n",
    "                print('4. -------> None:\\n')\n",
    "            \n",
    "            # right hand side trees\n",
    "            print('5. -------> Entering right of depth:',depth)\n",
    "            node_dict['right'] = self.grow_tree(x_data=x_right,\n",
    "                                               y_data=y_right,\n",
    "                                               feat_idx_list=feat_idx_list,\n",
    "                                               node_dict={},\n",
    "                                               max_depth=max_depth,\n",
    "                                               min_samples_split=min_samples_split,\n",
    "                                               min_samples_leaf=min_samples_leaf,\n",
    "                                               depth=depth+1)\n",
    "            if node_dict['right']==None:\n",
    "                print('6. --------> None:\\n')\n",
    "            \n",
    "            #print('After :\\n',node_dict)\n",
    "            #Error Handling\n",
    "            try:\n",
    "                self.depth += 1   # increase the depth since we call fit once\n",
    "            except:\n",
    "                print('7. -------> Entering except---')\n",
    "                return node_dict\n",
    "            \n",
    "        elif depth>max_depth:\n",
    "            return None\n",
    "        \n",
    "        elif (len(y_data)<min_samples_split) | (len(y_data)<min_samples_leaf):\n",
    "            return None\n",
    "        \n",
    "        elif node_dict is None:\n",
    "            return None\n",
    "\n",
    "        \n",
    "        #Returns the fully expanded tree\n",
    "        return node_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-consortium",
   "metadata": {
    "papermill": {
     "duration": 0.026321,
     "end_time": "2021-07-29T06:38:20.770863",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.744542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Invoking the UDF for the whole classification tree building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "framed-contrast",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:20.826596Z",
     "iopub.status.busy": "2021-07-29T06:38:20.825990Z",
     "iopub.status.idle": "2021-07-29T06:38:21.047522Z",
     "shell.execute_reply": "2021-07-29T06:38:21.046713Z",
     "shell.execute_reply.started": "2021-07-29T06:36:40.996660Z"
    },
    "papermill": {
     "duration": 0.24967,
     "end_time": "2021-07-29T06:38:21.047660",
     "exception": false,
     "start_time": "2021-07-29T06:38:20.797990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in init\n",
      "#---------------------------------- DEPTH : 0  -----------------------------------#\n",
      "{0: 0.47171505085580834}\n",
      "{1: 0.3310508721751884}\n",
      "{4: 0.440020146625283}\n",
      "{5: 0.46906867720264844}\n",
      "{7: 0.4574129473382337}\n",
      "{9: 0.47414944306555556}\n",
      "1. -------> Entering root_node of depth : 0\n",
      "2. ------->First :\n",
      " {'col': 'Sex', 'col_idx': 1, 'threshold': 0.0, 'val': 0.38636363636363635, 'n_class_0': 486, 'n_class_1': 306, 'n_vals': 792}\n",
      "3. -------> Entering left of depth: 0\n",
      "#---------------------------------- DEPTH : 1  -----------------------------------#\n",
      "{0: 0.37265443811933374}\n",
      "{1: nan}\n",
      "{4: 0.33847434922703745}\n",
      "{5: 0.3543193271546412}\n",
      "{7: 0.33123223334569263}\n",
      "{9: 0.37575147104496653}\n",
      "1. -------> Entering root_node of depth : 1\n",
      "2. ------->First :\n",
      " {'col': 'Family_size', 'col_idx': 7, 'threshold': 0.3, 'val': 0.7491039426523297, 'n_class_0': 70, 'n_class_1': 209, 'n_vals': 279}\n",
      "3. -------> Entering left of depth: 1\n",
      "#---------------------------------- DEPTH : 2  -----------------------------------#\n",
      "{0: 0.31660441426146}\n",
      "{1: nan}\n",
      "{4: 0.2969146460475941}\n",
      "{5: 0.3080478345184227}\n",
      "{7: 0.3190103509214845}\n",
      "{9: 0.31973421926910295}\n",
      "1. -------> Entering root_node of depth : 2\n",
      "2. ------->First :\n",
      " {'col': 'Pclass_1', 'col_idx': 4, 'threshold': 0.0, 'val': 0.8, 'n_class_0': 50, 'n_class_1': 200, 'n_vals': 250}\n",
      "3. -------> Entering left of depth: 2\n",
      "4. -------> None:\n",
      "\n",
      "5. -------> Entering right of depth: 2\n",
      "6. --------> None:\n",
      "\n",
      "7. -------> Entering except---\n",
      "5. -------> Entering right of depth: 1\n",
      "#---------------------------------- DEPTH : 2  -----------------------------------#\n",
      "{0: 0.3575989782886336}\n",
      "{1: nan}\n",
      "{4: 0.27586206896551707}\n",
      "{5: 0.3575989782886336}\n",
      "{7: 0.40583554376657827}\n",
      "{9: nan}\n",
      "1. -------> Entering root_node of depth : 2\n",
      "2. ------->First :\n",
      " {'col': 'Pclass_1', 'col_idx': 4, 'threshold': 0.0, 'val': 0.3103448275862069, 'n_class_0': 20, 'n_class_1': 9, 'n_vals': 29}\n",
      "3. -------> Entering left of depth: 2\n",
      "4. -------> None:\n",
      "\n",
      "5. -------> Entering right of depth: 2\n",
      "6. --------> None:\n",
      "\n",
      "7. -------> Entering except---\n",
      "7. -------> Entering except---\n",
      "5. -------> Entering right of depth: 0\n",
      "#---------------------------------- DEPTH : 1  -----------------------------------#\n",
      "{0: 0.30415432842779827}\n",
      "{1: nan}\n",
      "{4: 0.2891642204708224}\n",
      "{5: 0.30622009569378}\n",
      "{7: 0.3022124119303341}\n",
      "{9: 0.303683184569611}\n",
      "1. -------> Entering root_node of depth : 1\n",
      "2. ------->First :\n",
      " {'col': 'Pclass_1', 'col_idx': 4, 'threshold': 0.0, 'val': 0.18908382066276802, 'n_class_0': 416, 'n_class_1': 97, 'n_vals': 513}\n",
      "3. -------> Entering left of depth: 1\n",
      "#---------------------------------- DEPTH : 2  -----------------------------------#\n",
      "{0: 0.2387401820774909}\n",
      "{1: nan}\n",
      "{4: nan}\n",
      "{5: 0.2400903486038945}\n",
      "{7: 0.23635254521663485}\n",
      "{9: 0.23880749566535098}\n",
      "1. -------> Entering root_node of depth : 2\n",
      "2. ------->First :\n",
      " {'col': 'Family_size', 'col_idx': 7, 'threshold': 0.1, 'val': 0.1396508728179551, 'n_class_0': 345, 'n_class_1': 56, 'n_vals': 401}\n",
      "3. -------> Entering left of depth: 2\n",
      "4. -------> None:\n",
      "\n",
      "5. -------> Entering right of depth: 2\n",
      "6. --------> None:\n",
      "\n",
      "7. -------> Entering except---\n",
      "5. -------> Entering right of depth: 1\n",
      "#---------------------------------- DEPTH : 2  -----------------------------------#\n",
      "{0: 0.4293267651888342}\n",
      "{1: nan}\n",
      "{4: nan}\n",
      "{5: nan}\n",
      "{7: 0.45925324675324664}\n",
      "{9: nan}\n",
      "1. -------> Entering root_node of depth : 2\n",
      "2. ------->First :\n",
      " {'col': 'PassengerId', 'col_idx': 0, 'threshold': 186.0, 'val': 0.36607142857142855, 'n_class_0': 71, 'n_class_1': 41, 'n_vals': 112}\n",
      "3. -------> Entering left of depth: 2\n",
      "4. -------> None:\n",
      "\n",
      "5. -------> Entering right of depth: 2\n",
      "6. --------> None:\n",
      "\n",
      "7. -------> Entering except---\n",
      "7. -------> Entering except---\n",
      "7. -------> Entering except---\n"
     ]
    }
   ],
   "source": [
    "cart_ = cart()\n",
    "tree_dict_ = cart_.grow_tree(x_data=X_arr,\n",
    "                             y_data=y_arr,\n",
    "                             node_dict={},\n",
    "                             max_depth=2,\n",
    "                             input_ads_=input_ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-nicholas",
   "metadata": {
    "papermill": {
     "duration": 0.023003,
     "end_time": "2021-07-29T06:38:21.093654",
     "exception": false,
     "start_time": "2021-07-29T06:38:21.070651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## UDF for prediction of a single row in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caroline-princeton",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:21.147339Z",
     "iopub.status.busy": "2021-07-29T06:38:21.146711Z",
     "iopub.status.idle": "2021-07-29T06:38:21.150086Z",
     "shell.execute_reply": "2021-07-29T06:38:21.149404Z",
     "shell.execute_reply.started": "2021-07-29T06:36:41.286574Z"
    },
    "papermill": {
     "duration": 0.033355,
     "end_time": "2021-07-29T06:38:21.150242",
     "exception": false,
     "start_time": "2021-07-29T06:38:21.116887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def single_row_pred(test_x_,max_depth,temp_tree_dict): #Takes in the tree dict from training\n",
    "\n",
    "    for i in range(max_depth): #For all depth\n",
    "        \n",
    "        #print('------ depth :',i)\n",
    "        threshold = temp_tree_dict['threshold']\n",
    "        split_col_idx = temp_tree_dict['col_idx']\n",
    "\n",
    "        tree_dict_left = temp_tree_dict['left']\n",
    "        tree_dict_right = temp_tree_dict['right']\n",
    "        \n",
    "        #Traversing into left side\n",
    "        if (test_x_[split_col_idx]<=threshold) & (tree_dict_left!=None) & (tree_dict_right!=None):\n",
    "\n",
    "            temp_tree_dict = tree_dict_left\n",
    "\n",
    "            if (temp_tree_dict['left']==None) & (temp_tree_dict['right']==None):\n",
    "                prediction = temp_tree_dict['val']\n",
    "                #pred_list.append(prediction)\n",
    "\n",
    "        #Traversing into right side\n",
    "        elif (test_x_[split_col_idx]>threshold) & (tree_dict_left!=None) & (tree_dict_right!=None):\n",
    "\n",
    "            temp_tree_dict = tree_dict_right\n",
    "\n",
    "            if (temp_tree_dict['left']==None) & (temp_tree_dict['right']==None):\n",
    "                prediction = temp_tree_dict['val']\n",
    "                #pred_list.append(prediction)\n",
    "\n",
    "        #If end of the tree is reached, generate predictions \n",
    "        elif (tree_dict_left==None) & (tree_dict_right==None):\n",
    "\n",
    "            prediction = temp_tree_dict['val']\n",
    "            \n",
    "            \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-inspector",
   "metadata": {
    "papermill": {
     "duration": 0.023324,
     "end_time": "2021-07-29T06:38:21.196573",
     "exception": false,
     "start_time": "2021-07-29T06:38:21.173249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## UDF for prediction overall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "behind-ratio",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:21.249540Z",
     "iopub.status.busy": "2021-07-29T06:38:21.248887Z",
     "iopub.status.idle": "2021-07-29T06:38:21.251328Z",
     "shell.execute_reply": "2021-07-29T06:38:21.251712Z",
     "shell.execute_reply.started": "2021-07-29T06:36:41.296545Z"
    },
    "papermill": {
     "duration": 0.031939,
     "end_time": "2021-07-29T06:38:21.251876",
     "exception": false,
     "start_time": "2021-07-29T06:38:21.219937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_tree(test_data,max_depth,tree_object=tree_dict_,threshold=0.5): #Takes in tree dictionary and threshold of proabability\n",
    "    \n",
    "    pred_list = []\n",
    "    \n",
    "    #For each row in test data\n",
    "    for idx in range(len(test_data)):\n",
    "        \n",
    "        #Sngle row prediction calculation\n",
    "        pred = np.round(single_row_pred(test_x_=test_data[idx],\n",
    "                                        max_depth=max_depth,\n",
    "                                        temp_tree_dict=tree_object),3)\n",
    "        pred_list.append(pred)\n",
    "        \n",
    "    print('Length of preds :',len(pred_list))\n",
    "    \n",
    "    #Converting into array\n",
    "    pred_proba = np.array(pred_list)\n",
    "    \n",
    "    #Converting into class predictions (binary) based on threshold\n",
    "    pred_list = (np.array(pred_proba)>threshold).astype(int)\n",
    "        \n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-missile",
   "metadata": {
    "papermill": {
     "duration": 0.022531,
     "end_time": "2021-07-29T06:38:21.297879",
     "exception": false,
     "start_time": "2021-07-29T06:38:21.275348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Invoking prediction UDF (Generating predictions from the manual decision tree classification model on the test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "comprehensive-commitment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:21.352600Z",
     "iopub.status.busy": "2021-07-29T06:38:21.351224Z",
     "iopub.status.idle": "2021-07-29T06:38:21.365453Z",
     "shell.execute_reply": "2021-07-29T06:38:21.365845Z",
     "shell.execute_reply.started": "2021-07-29T06:36:41.308382Z"
    },
    "papermill": {
     "duration": 0.045305,
     "end_time": "2021-07-29T06:38:21.366008",
     "exception": false,
     "start_time": "2021-07-29T06:38:21.320703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of preds : 100\n",
      "Total predictions : 100\n",
      "Unique of predictions : [0 1]\n",
      "1. ROC AUC: 0.779\n",
      "2. Accuracy : 0.81\n",
      "3. Classification Report -\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86        64\n",
      "           1       0.77      0.67      0.72        36\n",
      "\n",
      "    accuracy                           0.81       100\n",
      "   macro avg       0.80      0.78      0.79       100\n",
      "weighted avg       0.81      0.81      0.81       100\n",
      "\n",
      "4. Confusion Matrix - \n",
      " [[57  7]\n",
      " [12 24]]\n"
     ]
    }
   ],
   "source": [
    "preds_manual = predict_tree(test_data=X_test_arr\n",
    "                            ,max_depth=2,\n",
    "                            tree_object=tree_dict_,\n",
    "                            threshold=0.5)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "print('Total predictions :', len(preds_manual))\n",
    "print('Unique of predictions :',np.unique(preds_manual))\n",
    "preds_manual[0:10]\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------\n",
    "#Evaluating the model\n",
    "score = roc_auc_score(y_test_arr, preds_manual)\n",
    "print('1. ROC AUC: %.3f' % score)\n",
    "print('2. Accuracy :',accuracy_score(y_test_arr, preds_manual))\n",
    "print('3. Classification Report -\\n',classification_report(y_test_arr, preds_manual))\n",
    "print('4. Confusion Matrix - \\n',confusion_matrix(y_test_arr, preds_manual))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-numbers",
   "metadata": {
    "papermill": {
     "duration": 0.022993,
     "end_time": "2021-07-29T06:38:21.412487",
     "exception": false,
     "start_time": "2021-07-29T06:38:21.389494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Insights : We got an accuracy of 81% with ~0.78 ROC AUC, very good for a manually implemented model!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-female",
   "metadata": {
    "papermill": {
     "duration": 0.023883,
     "end_time": "2021-07-29T06:38:21.459832",
     "exception": false,
     "start_time": "2021-07-29T06:38:21.435949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sklearn Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "computational-father",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-29T06:38:21.512962Z",
     "iopub.status.busy": "2021-07-29T06:38:21.512362Z",
     "iopub.status.idle": "2021-07-29T06:38:21.732555Z",
     "shell.execute_reply": "2021-07-29T06:38:21.732044Z",
     "shell.execute_reply.started": "2021-07-29T06:37:45.266300Z"
    },
    "papermill": {
     "duration": 0.249522,
     "end_time": "2021-07-29T06:38:21.732712",
     "exception": false,
     "start_time": "2021-07-29T06:38:21.483190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ROC AUC: 0.779\n",
      "2. Accuracy : 0.81\n",
      "3. Classification Report -\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86        64\n",
      "           1       0.77      0.67      0.72        36\n",
      "\n",
      "    accuracy                           0.81       100\n",
      "   macro avg       0.80      0.78      0.79       100\n",
      "weighted avg       0.81      0.81      0.81       100\n",
      "\n",
      "4. Confusion Matrix - \n",
      " [[57  7]\n",
      " [12 24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=100,max_depth=2,min_samples_split=5,min_samples_leaf=2)\n",
    "dt_clf.fit(X_arr[:,[0,1,4,5,7,9]],y_arr)\n",
    "\n",
    "sklearn_preds = dt_clf.predict(X_test_arr[:,[0,1,4,5,7,9]])\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "#Evaluating the model\n",
    "score = roc_auc_score(y_test_arr, sklearn_preds)\n",
    "print('1. ROC AUC: %.3f' % score)\n",
    "print('2. Accuracy :',accuracy_score(y_test_arr, sklearn_preds))\n",
    "print('3. Classification Report -\\n',classification_report(y_test_arr, sklearn_preds))\n",
    "print('4. Confusion Matrix - \\n',confusion_matrix(y_test_arr, sklearn_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-kruger",
   "metadata": {
    "papermill": {
     "duration": 0.023082,
     "end_time": "2021-07-29T06:38:21.780872",
     "exception": false,
     "start_time": "2021-07-29T06:38:21.757790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Insights : The manual implementation performance is exactly the same as the skelarn version with same hyper-params, indicating correct implementation!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-munich",
   "metadata": {
    "papermill": {
     "duration": 0.023155,
     "end_time": "2021-07-29T06:38:21.827272",
     "exception": false,
     "start_time": "2021-07-29T06:38:21.804117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-adaptation",
   "metadata": {
    "papermill": {
     "duration": 0.023172,
     "end_time": "2021-07-29T06:38:21.873631",
     "exception": false,
     "start_time": "2021-07-29T06:38:21.850459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.721792,
   "end_time": "2021-07-29T06:38:22.606382",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-29T06:38:10.884590",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
